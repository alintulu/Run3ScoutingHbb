{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e04a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed to import lumiacc \n",
    "import sys\n",
    "sys.path.append('/afs/cern.ch/work/a/adlintul/public/scouting/hbb/analysis/Run3ScoutingHbb')\n",
    "from processors import lumiacc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hist\n",
    "from hist import Hist\n",
    "import awkward as ak\n",
    "import json\n",
    "import uproot\n",
    "import math\n",
    "from coffea import util\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep\n",
    "plt.style.use(mplhep.style.CMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248164a7",
   "metadata": {},
   "source": [
    "# Table of contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "* [Scaling MC by cross section and luminosity](#scaling)\n",
    "* [Grouping data together](#grouping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e453e4a",
   "metadata": {},
   "source": [
    "# Scaling MC by cross section and luminosity <a class=\"anchor\" id=\"scaling\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0930e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert directory from which the MC samples are read. Here I am reading the samples\n",
    "# from the \"hist\" step (i.e. creation of the final histogram).\n",
    "step = \"hist\"\n",
    "out_dir = f\"../outfiles/Run3Summer22EE/{step}\"\n",
    "\n",
    "# Insert lumi in units of /pb\n",
    "total_lumi = 100 * 1000\n",
    "\n",
    "# Read cross section of each dataset\n",
    "with open(\"../data/xsec/xsec.json\", \"r\") as json_file:\n",
    "    xs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51b8842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../outfiles/Run3Summer22EE/hist/dask_QCD.coffea\n",
      "Loading ../outfiles/Run3Summer22EE/hist/dask_Zto2Q-4Jets.coffea\n",
      "Loading ../outfiles/Run3Summer22EE/hist/dask_Wto2Q-3Jets.coffea\n",
      "Loading ../outfiles/Run3Summer22EE/hist/dask_TT.coffea\n",
      "Loading ../outfiles/Run3Summer22EE/hist/dask_VV.coffea\n",
      "Loading ../outfiles/Run3Summer22EE/hist/dask_Hto2B.coffea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_104/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/hist/basehist.py:99: UserWarning: Please use 'Weight()' instead of 'Weight'\n",
      "  warnings.warn(msg)\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_104/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/hist/basehist.py:325: UserWarning: List indexing selection is experimental. Removed bins are not placed in overflow.\n",
      "  return super().__getitem__(self._index_transform(index))\n"
     ]
    }
   ],
   "source": [
    "# This cell scales the MC histograms by cross section and luminosity.\n",
    "# It also groups various related datasets into a single processes, e.g.\n",
    "# ['TTto2L2Nu', 'TTtoLNu2Q', 'TTto4Q] => TTbar\n",
    "\n",
    "from collections import defaultdict \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "outsum = defaultdict()\n",
    "\n",
    "started = 0\n",
    "\n",
    "for file in [\n",
    "    \"dask_QCD.coffea\",\n",
    "    \"dask_Zto2Q-4Jets.coffea\",\n",
    "    \"dask_Wto2Q-3Jets.coffea\",\n",
    "    \"dask_TT.coffea\",\n",
    "    \"dask_VV.coffea\",\n",
    "    \"dask_Hto2B.coffea\",\n",
    "]:\n",
    "    \n",
    "    filename = f\"{out_dir}/{file}\"\n",
    "\n",
    "    print(\"Loading \"+filename)\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        out = util.load(filename)[0]\n",
    "\n",
    "        if started == 0:\n",
    "            outsum['templates'] = out['hist']\n",
    "            outsum['sumw'] = out['sumw']\n",
    "            started += 1\n",
    "        else:\n",
    "            outsum['templates'] += out['hist']\n",
    "            for k,v in out['sumw'].items():\n",
    "                outsum['sumw'][k] = v\n",
    "        del out\n",
    "    else:\n",
    "        print(filename + \" does not exist\")\n",
    "                \n",
    "# \"dataset\" has to be first for the scaling to work\n",
    "outsum[\"templates\"] = outsum[\"templates\"].project('dataset', 'mass', 'pt', 'disc', 'genflav', 'systematic')\n",
    "\n",
    "scale_lumi = {k: xs[k] * total_lumi / w for k, w in outsum['sumw'].items()}\n",
    "\n",
    "for i, name in enumerate(outsum[\"templates\"].axes[\"dataset\"]):\n",
    "    outsum[\"templates\"].view(flow=True)[i] *= scale_lumi[name]\n",
    "\n",
    "def group(h: hist.Hist, oldname: str, newname: str, grouping: dict):\n",
    "    hnew = hist.Hist(\n",
    "        hist.axis.StrCategory(grouping, name=newname),\n",
    "        *(ax for ax in h.axes if ax.name != oldname),\n",
    "        storage=h._storage_type,\n",
    "    )\n",
    "    for i, indices in enumerate(grouping.values()):\n",
    "        hnew.view(flow=True)[i] = h[{oldname: indices}][{oldname: sum}].view(flow=True)\n",
    "\n",
    "    return hnew\n",
    "\n",
    "grouping = {\n",
    "    'TTbar' : ['TTto2L2Nu', 'TTtoLNu2Q', 'TTto4Q'],\n",
    "    'QCD' : ['QCD_PT-120to170', 'QCD_PT-170to300', 'QCD_PT-1000to1400', 'QCD_PT-1400to1800', 'QCD_PT-1800to2400', 'QCD_PT-300to470', 'QCD_PT-2400to3200', 'QCD_PT-800to1000', 'QCD_PT-600to800', 'QCD_PT-470to600'],\n",
    "    'ZJets' : ['Zto2Q-4Jets_HT-200to400', 'Zto2Q-4Jets_HT-800', 'Zto2Q-4Jets_HT-600to800', 'Zto2Q-4Jets_HT-400to600'],\n",
    "    'W' : ['Wto2Q-3Jets_HT-200to400', 'Wto2Q-3Jets_HT-800', 'Wto2Q-3Jets_HT-600to800', 'Wto2Q-3Jets_HT-400to600'],\n",
    "    'VV' : ['WWto2L2Nu', 'WWto4Q', 'ZZto2L2Nu', 'ZZto2Nu2Q', 'ZZto2L2Q', 'WWtoLNu2Q', 'WZtoLNu2Q', 'WZto3LNu', 'WZto2L2Q'],\n",
    "    'Bkg. H' : ['ggZH_Hto2B_Zto2L_M-125', 'ZH_Hto2B_Zto2L_M-125', 'ZH_Hto2B_Zto2Q_M-125', 'WplusH_Hto2B_WtoLNu_M-125', 'WminusH_Hto2B_WtoLNu_M-125', 'WplusH_Hto2B_Wto2Q_M-125', 'WminusH_Hto2B_Wto2Q_M-125', 'VBFHto2B_M-125_dipoleRecoilOn', 'ggZH_Hto2B_Zto2Q_M-125', 'ttHto2B_M-125', 'ggZH_Hto2B_Zto2Nu_M-125'],\n",
    "    'ggF' : ['GluGluHto2B_PT-200_M-125'],\n",
    "    'VBF' : ['VBFHto2B_M-125_dipoleRecoilOn'],\n",
    "    'WH' : ['WplusH_Hto2B_WtoLNu_M-125', 'WminusH_Hto2B_WtoLNu_M-125', 'WplusH_Hto2B_Wto2Q_M-125', 'WminusH_Hto2B_Wto2Q_M-125'],\n",
    "    'ZH' : ['ggZH_Hto2B_Zto2L_M-125', 'ggZH_Hto2B_Zto2Q_M-125', 'ggZH_Hto2B_Zto2Nu_M-125', 'ZH_Hto2B_Zto2L_M-125', 'ZH_Hto2B_Zto2Q_M-125'],\n",
    "    'ttH' : ['ttHto2B_M-125'],\n",
    "}\n",
    "\n",
    "output = group(outsum[\"templates\"], \"dataset\", \"process\", grouping)\n",
    "\n",
    "del outsum\n",
    "\n",
    "picklename = f\"{out_dir}/mc.pkl\"\n",
    "if os.path.isfile(picklename):\n",
    "    os.remove(picklename)\n",
    "\n",
    "outfile = open(picklename, 'wb')\n",
    "pickle.dump({\n",
    "        \"hist\" : output,\n",
    "        \"lumi\" : total_lumi,\n",
    "    }, outfile, protocol=-1)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094309f8",
   "metadata": {},
   "source": [
    "# Grouping collision data together <a class=\"anchor\" id=\"grouping\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b453952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert directory from which the data samples are read. Here I am reading the samples\n",
    "# from the \"cutflow\" step.\n",
    "\n",
    "step = \"cutflow\"\n",
    "out_dir = f\"../outfiles/Run3Summer22EE/{step}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a778eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total lumi: 19647.58 /pb\n",
      "Total lumi: 19.65 /fb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_104/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/hist/basehist.py:99: UserWarning: Please use 'Weight()' instead of 'Weight'\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "import os\n",
    "from coffea.lumi_tools import LumiData, LumiList\n",
    "\n",
    "path_lumi_csv = \"../data/lumi/Run3_2022_2023_Golden2.csv\"\n",
    "lumidata = LumiData(path_lumi_csv)\n",
    "\n",
    "outsum = defaultdict()\n",
    "total_lumi = 0\n",
    "\n",
    "started = 0\n",
    "with open(\"../data/inputfiles/Run3Summer22EE/data/files.txt\") as f:\n",
    "    filelist = [line.rstrip() for line in f]\n",
    "    \n",
    "for file in filelist:\n",
    "    filename = f\"{out_dir}/{file}\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        out = util.load(filename)[0]\n",
    "        \n",
    "        for dataset, lumilist in out['lumilist'].items():\n",
    "            lumi_list = out['lumilist'][dataset]\n",
    "            lumi_list.unique()\n",
    "            lumi = lumidata.get_lumi(lumi_list)\n",
    "            total_lumi += lumi\n",
    "            \n",
    "        if started == 0:\n",
    "            outsum['templates'] = out['hist']\n",
    "            outsum['sumw'] = out['sumw']\n",
    "            started += 1\n",
    "        else:\n",
    "            outsum['templates'] += out['hist']\n",
    "            for k,v in out['sumw'].items():\n",
    "                outsum['sumw'][k] = v\n",
    "        del out\n",
    "\n",
    "print()\n",
    "print(f\"Total lumi: {total_lumi:.2f} /pb\")\n",
    "print(f\"Total lumi: {total_lumi/1000:.2f} /fb\")\n",
    "        \n",
    "def group(h: hist.Hist, oldname: str, newname: str, grouping: dict):\n",
    "    hnew = hist.Hist(\n",
    "        hist.axis.StrCategory(grouping, name=newname),\n",
    "        *(ax for ax in h.axes if ax.name != oldname),\n",
    "        storage=h._storage_type,\n",
    "    )\n",
    "    for i, indices in enumerate(grouping.values()):\n",
    "        hnew.view(flow=True)[i] = h[{oldname: sum}].view(flow=True)\n",
    "\n",
    "    return hnew\n",
    "        \n",
    "grouping = {\n",
    "    'Run3Summer22EE': []\n",
    "}\n",
    "\n",
    "output = group(outsum[\"templates\"], \"dataset\", \"process\", grouping)\n",
    "\n",
    "del outsum\n",
    "\n",
    "picklename = f\"{out_dir}/data.pkl\"\n",
    "if os.path.isfile(picklename):\n",
    "    os.remove(picklename)\n",
    "\n",
    "outfile = open(picklename, 'wb')\n",
    "pickle.dump(output, outfile, protocol=-1)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106e3de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
